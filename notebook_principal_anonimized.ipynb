{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cruz-marco/Recommender-DNC/blob/main/notebook_principal_anonimized.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52dZ2_2JbVZk"
      },
      "source": [
        "# 1.0 Requerimentos do ambiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6UXniOObVZm"
      },
      "source": [
        "Foi criado um ambiente usando o venv para o desenvolvimento do modelo, este ambiente isolado usa Python versão 3.10.6 e as seguintes bibliotecas são necessárias para seu pleno funcionamento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9LvAmLKQXRN",
        "outputId": "064f1ab8-1b17-46af-fe80-95ad5f2439fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "pymongo==4.3.2\n",
        "sklearn==1.1.3\n",
        "numpy==1.23.4\n",
        "mlflow==2.0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckG67Vo2bVZo"
      },
      "source": [
        "O código foi escrito seguindo as recomendações sugeridas nas documentações das bibliotecas, portanto, existem outras versões que podem ser usadas sem muito prejuízo esperado no funcionamento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5kXD-mZbVZo"
      },
      "source": [
        "O MLflow foi usado para fins de monitoramento. Nos foi informado que há o desenvolvimento de uma solução para este fim por parte da AoCubo, então a princípio, ele é opcional, encontra-se implementado, porém, desativado conforme os códigos a seguir."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGCZBfyQbVZo"
      },
      "source": [
        "# 2.0 Conexões com o banco de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6_nymPibVZo"
      },
      "source": [
        "## 2.1 Ponto de atenção\n",
        "\n",
        "- A constante 'OUTPUT_NAME' faz referência à coleção onde a matriz de similaridade será salva e está sem um valor definido. Ela é usada pela função 'matrix_saver' que armazena toda a matriz de similaridade no banco de dados. Não testamos no ambiente de produção da AoCubo (apesar de termos acesso aos dados, jamais seria interessante atrapalhar o funcionamento do modelo vigente), mas pode ser facilmente configurado adicionando uma string com o nome da coleção.\n",
        "\n",
        "- A função 'matrix_saver' está implementada no módulo de treinamento, entretanto desativada com um comentário. É aconselhável fazer uso dela em um ambiente de teste controlado, até para verificar o formato da matriz."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0vIx7Ya5bVZp",
        "outputId": "a36d4d54-d556-4dab-b51f-5f455c88e1f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting database.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile database.py\n",
        "from pymongo import MongoClient\n",
        "\n",
        "\n",
        "#String de conexão com o mongodb\n",
        "CONNECT_STRING = None\n",
        "\n",
        "#Nome da base de dados\n",
        "DB_NAME = None #Nome da coleção que será consumida pelo treinamento do modelo\n",
        "INPUT_NAME = 'data_portal' #Nome da coleção onde estão os dados de entrada.\n",
        "OUTPUT_NAME = None #Nome da coleção onde será armazenada a matriz de similaridade.\n",
        "\n",
        "client = MongoClient(CONNECT_STRING) #Criando o cliente de acesso\n",
        "db = client[DB_NAME]#Selecionando o banco de dados\n",
        "\n",
        "# Função para receber os dados em formato de lista.\n",
        "def data_getter():\n",
        "    return list(db[INPUT_NAME].find())\n",
        "\n",
        "# Função para salvar a matriz no banco de dados.\n",
        "def matrix_saver(matrix):\n",
        "    return db[OUTPUT_NAME].insert_many(matrix.to_dict('records'))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOB1aSoBbVZq"
      },
      "source": [
        "# 3.0 Funções de utilidades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAa5pqK0bVZq"
      },
      "source": [
        "Módulo que contém as funções de utilidades utilizadas no treinamento do modelo:\n",
        "\n",
        "- 'pre_processer': É a função responsável pela verificação de valores duplicados, zerados ou faltantes; fazendo a verificação e remoção, caso hajam na massa a ser utilizada para o treinamento.\n",
        "\n",
        "- 'matrix_mounter': A saída do modelo faz alusão somente ao índice do array que é consumido pelo NearestNeighbors. Portanto, esta função transtorma o array em Pandas DataFrame, nomeia as colunas e transtorma os índices em 'unit_id', referenciando os valores com o índice da massa de treinamento processada."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5DozUYFuB-s",
        "outputId": "04f5064a-efc7-4249-e428-28441221f73a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting functions.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile functions.py\n",
        "from pymongo import MongoClient\n",
        "import pandas as pd\n",
        "\n",
        "def pre_processer(df):\n",
        "  \"\"\"\n",
        "  Função criada para remover os dados nulos e faltantes antes do \n",
        "  treinamento do modelo.\n",
        "\n",
        "  df: DataFrame montado a partir dos dados 'brutos' do MongoDB\n",
        "  return: DataFrame sem zeros e valores faltantes.\n",
        "  \"\"\"\n",
        "  #Eliminando valores duplicados\n",
        "  if df.duplicated().sum() > 0:\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "  #Eliminando registros nulos\n",
        "  if df.isna().sum().sum() > 0:\n",
        "    df = df.dropna(how='any')\n",
        "\n",
        "  #Eliminando registros com preço = 0\n",
        "  if (df['price'] == 0).sum() > 0:\n",
        "    df = df.drop(\n",
        "        index=df[(df['price'] == 0)]\\\n",
        "        .index\n",
        "    )\n",
        "  return df\n",
        "\n",
        "\n",
        "def matrix_mounter(neighbors, df_processed):\n",
        "    \"\"\"\n",
        "    Função para montagem da matriz de semelhança usando os \n",
        "    índicies dos neighbors retornados pelo NearestNeighbors\n",
        "\n",
        "    neighbors:  Array com os índices\n",
        "    df_processed: Dataframe usado para o treinamento do modelo\n",
        "    return: Matriz de similaridade processada com os ID's dos imóveis\n",
        "    \"\"\"\n",
        "    s_matrix = pd.DataFrame(neighbors)\\\n",
        "    .apply(lambda x: df_processed.index[x])\\\n",
        "    .rename(columns={\n",
        "        0: 'unit_id',\n",
        "        1: 'neighbor_1',\n",
        "        2: 'neighbor_2',\n",
        "        3: 'neighbor_3',\n",
        "        4: 'neighbor_4',\n",
        "        5: 'neighbor_5',\n",
        "        6: 'neighbor_6',\n",
        "        7: 'neighbor_7',\n",
        "    })\\\n",
        "    .set_index('unit_id')\n",
        "\n",
        "    return s_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aXv0A7BbVZr"
      },
      "source": [
        "# 4.0 Processamento de dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVV4OyTQbVZs"
      },
      "source": [
        "Módulo onde acontece efetivamente o processamento de dados.\n",
        "\n",
        "1. O DataFrame principal é montado a partir dos dados que estão na coleção 'data_portal' no MongoDB com as features selecionadas;\n",
        "2. O conjunto de dados é verificado e tem os nulos, duplicados e sem valores eliminados;\n",
        "3. É aplicada a transformação logarítmica em 'living_area' e 'price';\n",
        "4. Os dados são escalonados usando o MinMaxScaler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIB6jTrNQDuJ",
        "outputId": "f47a91fa-c309-4b62-f2ff-9599aecf3112"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting data_processing.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile data_processing.py\n",
        "#Preprocessamento de dados\n",
        "from database import data_getter\n",
        "from functions import pre_processer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#Definição das variáveis de interesse\n",
        "FEATURES = ['bathrooms', 'bedrooms', 'living_area', 'latitude',\n",
        "            'longitude', 'price', 'property_type_id']\n",
        "\n",
        "#Montagem do dataframe principal\n",
        "df = pd.DataFrame(\n",
        "    data = data_getter()    \n",
        "    ).set_index(\n",
        "        'unit_id'\n",
        "    )[FEATURES] \n",
        "\n",
        "df = pre_processer(df)\n",
        "\n",
        "#Aplicando o log em living_area e em price\n",
        "df[['living_area', 'price']] = np.log(df[['living_area', 'price']])\n",
        "\n",
        "#Aplicando o MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(df)\n",
        "scaled_feats = scaler.transform(df)\n",
        "\n",
        "df[FEATURES] = scaled_feats\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLiNT4kabVZs"
      },
      "source": [
        "# 5.0 Treinamento do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9QbjIHgbVZs"
      },
      "source": [
        "Módulo principal do recomendador.\n",
        "\n",
        "Neste módulo, que deve ser executado sempre que quisermos treinar o modelo, o NearestNeighbors consome a base de dados processada para o seu treinamento e, em seguida, a consome mais uma vez para criar a matriz de similaridade.\n",
        "\n",
        "Existe uma implementação do MLflow pronta abaixo (basta ela ser descomentada), bem básica, mas que pode ajudar no monitoramento do modelo, enquanto a solução proprietária da AoCubo ainda não estiver pronta, caso achem necessário.\n",
        "\n",
        "A função 'matrix_evaluator' retorna um DataFrame de amostragem aleatória de 15 imóveis, com suas respectivas características e distâncias de cosseno, para a avaliação do modelo. Conforme implementada abaixo, ela salva este teste em formato html na pasta 'test_logs', mas pode ser alterada conforme for de interesse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlkP-dl8YNPR",
        "outputId": "6a52adc2-fa4b-4332-eb08-3f9f209ccfae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting model_training.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model_training.py\n",
        "#Treinamento do modelo\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from data_processing import df\n",
        "from functions import matrix_mounter\n",
        "from database import matrix_saver\n",
        "from quality_eval import matrix_evaluator\n",
        "import datetime\n",
        "#import mlflow\n",
        "\n",
        "run_name = f'KNN_Train_{str(datetime.datetime.now())}'\n",
        "#mlflow.set_experiment(run_name)\n",
        "\n",
        "#mlflow.start_run()\n",
        "\n",
        "model = NearestNeighbors(n_neighbors=8, metric='cosine', algorithm='brute', \n",
        "                        n_jobs=-1)\n",
        "\n",
        "#mlflow.log_params(model.get_params())\n",
        "\n",
        "\n",
        "model.fit(df.to_numpy())\n",
        "\n",
        "#Executando a predição. Retornando as distâncias e os índices dos vizinhos.\n",
        "distances, neighbors = model.kneighbors(X=df.to_numpy())\n",
        "\n",
        "#Monta a matriz de similaridade em um DataFrame, com os índices substituídos\n",
        "#pelos 'unity_id' dos imóveis.\n",
        "similarity_matrix = matrix_mounter(neighbors, df)\n",
        "\n",
        "#Salva um dataframe em html na pasta test_logs para avaliação qualitativa do modelo. Pode ser desabilitada caso necessário.\n",
        "matrix_evaluator(similarity_matrix, distances).to_html(f'./test_logs/{run_name}.html') \n",
        "#mlflow.log_artifact(f'./test_logs/{run_name}.html')\n",
        "\n",
        "\n",
        "#matrix_saver(similarity_matrix) #Retirar este comentário somente depois de verificar todo o código referente ao banco de dados.\n",
        "\n",
        "#mlflow.end_run()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8sPeG8tbVZt"
      },
      "source": [
        "# 6.0 Avaliação da qualidade das recomendações"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHqhTXLxbVZt"
      },
      "source": [
        "Módulo que contém somente a função de avaliação do modelo.\n",
        "\n",
        "Esta função foi baseada numa função muito mais básica utilizada na sprint de 'Evaluation' do CRISP-DM, entretanto esta, muito mais robusta e complexa, retorna um dataframe com as recomendações e o imóvel de referência para uma amostragem aleatória de 15 imóveis amparados pela matriz de similaridade."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "wqrO9MQE9fVz",
        "outputId": "70a753e7-d25e-4cee-a6a8-1d0d76b31656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting quality_eval.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile quality_eval.py\n",
        "from database import data_getter\n",
        "from data_processing import FEATURES\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.options.display.float_format = '{:,.6f}'.format\n",
        "\n",
        "\n",
        "def matrix_evaluator(sim_matrix, dists):\n",
        "  #Buscando propriedades dos imóveis\n",
        "  properties = pd.DataFrame(\n",
        "                data = data_getter()    \n",
        "                ).set_index(\n",
        "                    'unit_id'\n",
        "                )[FEATURES]\\\n",
        "                  .drop_duplicates()\n",
        "\n",
        "  p_cols = list(properties.reset_index().columns) #Salvando a lista com nomes das colunas\n",
        "\n",
        "  SAMPLE_SIZE = 15 #quantidade de registros para avaliação da amostra.\n",
        "\n",
        "  #Buscando as distâncias para avaliação\n",
        "  dists = pd.DataFrame(dists, index=sim_matrix.index)\\\n",
        "          .drop(columns=[0])\\\n",
        "          .rename(columns={\n",
        "          1: 'neighbor_1',\n",
        "          2: 'neighbor_2',\n",
        "          3: 'neighbor_3',\n",
        "          4: 'neighbor_4',\n",
        "          5: 'neighbor_5',\n",
        "          6: 'neighbor_6',\n",
        "          7: 'neighbor_7'\n",
        "          })\n",
        "\n",
        "  #Gerando uma amostra aleatória\n",
        "  samples = list(np.random.choice(sim_matrix.index, size=SAMPLE_SIZE))\n",
        "\n",
        "  eval_df = pd.DataFrame()# Dataframe principal a ser retornado\n",
        "\n",
        "  #Gerando uma linha em branco no dataframe\n",
        "  blanked = pd.Series({k:v for (k,v) in zip(p_cols, \n",
        "                      ['---' for _ in range(len(p_cols))])})\\\n",
        "                      .to_frame().T\n",
        "  blanked['distancies'] = '---'\n",
        "\n",
        "  titles = pd.Series({k:v for (k,v) in zip(p_cols, p_cols)}).to_frame().T\n",
        "  titles['distancies'] = 'distancies'\n",
        "\n",
        "  #Loop para buscar as informações dos imóveis, cruzando com os IDs da matriz de similaridade.\n",
        "  for sample in samples:\n",
        "    #Busca as infos do imóvel de referência.\n",
        "    ref = pd.DataFrame(properties.loc[sample]).T\\\n",
        "      .reset_index()\\\n",
        "      .rename(columns={'index': 'unit_id'})\n",
        "    ref['distancies'] = 'reference'\n",
        "\n",
        "    #Basca as infos das recomendações\n",
        "    recs = properties.loc[sim_matrix.loc[sample].to_list()].reset_index()\n",
        "    recs['distancies'] = dists.T[int(sample)].reset_index(drop=True)\n",
        "    \n",
        "    #Junta tudo neste DF\n",
        "    joined = pd.concat([ref, recs]).reset_index(drop=True)\n",
        "\n",
        "    #Acumula no DF principal de avaliação\n",
        "    eval_df = pd.concat([eval_df, joined, blanked, titles])\n",
        "\n",
        "  eval_df = eval_df.reset_index(drop=True)\n",
        "  eval_df.drop(index=list(eval_df.iloc[-2:].index), inplace=True)\n",
        "\n",
        "  return eval_df\n",
        "  "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "ds",
      "language": "python",
      "name": "ds"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "2f0cad72f76d414b876134b2b6c885b16a8840b5bd43fab039ff85b0da4a9f6d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}